\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{subfigure}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
%\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{Scene Text Recognition in the Wild}

\author{Chen-Yu Lee\\
{\tt\small chl260@ucsd.edu}
\and
Phuc Xuan Nguyen\\
{\tt\small pxn002@ucsd.edu}
}

\maketitle
\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
This paper demonstrates an algorithm to tackle the problem of reading text in ``natural'' photos. In contrast to the traditional OCR problem, for which the focus was on scanned pages, scene text presents a number of challenges more commonly associated with general object recognition, including different viewpoints, sizes/scale, locations, fronts, and styles (neon, graffiti). There are two main contributions of this work: The first is the novel character detector using more representative information in the training step and support vector machine based classifier. The second is a more general word recognition system by setting up the relaxation of a non-convex Quadratic Programming problem. We show a novel approach to tackle this problem without the explicit guide from a lexicon.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

For most people, a visual display of information is the fastest and most direct way to receive external information, through activities such as billboards and neon signs. However, for the visually impaired, it cannot be conveyed via the visual way to obtain information. In this paper, scene text recognition technique can be used in natural environments, so that the visually impaired person can access to the environmental information in texts.

Scene text recognition could also help improve map services. House number and store name recognition helps improve address geocoding. In most countries, very few addresses have associated geographic coordinates. The geocodes of the majority of addresses is therefore usually computed by interpolating the geocodes of neighboring addresses. Such interpolation introduces errors which may be significant, and may result in poor user experience. With the vehicle's location, the house number and the store name, a better map service of the building of interest can be computed in a straightforward way.

\begin{figure}[t]
\begin{center}
\includegraphics[width=1\linewidth]{fig/p1}
\includegraphics[width=1\linewidth]{fig/p10}
\end{center}
   \caption{Examples of character detection and word recognition.}
\label{fig:sample1}
\end{figure}

Smith and Learned-Miller~\cite{118} showe that the similarity among characters could be used to improve scene text recognition. They use bottom-up design by starting with hand segmentations of each character in the form of a rectangular bounding box, then the similarity expert performs on all pairs of bounding boxes within one word to higher the confident score of boxes that are the same in both signal and label spaces. This approach required highly rectified candidate bounding boxes (segmented by hand in~\cite{118}) to obtain reliable similarity output.

Neumann and Matas~\cite{120,119} use tradition pipelines for text recognition that their system first performs text localization by sequential selection from the set of Extremal Regions(ERs), and then use character segmentation approach to produce input for traditional Optical Character Recognition (OCR) engine. While this algorithm rely on stability of both text localization and segmentation procedure.

Netzer et al.,~\cite{121} detect and read house numbers from street level photos using unsupervised feature learning method. They show a robust feature learning approach that does not need to use any existing image descriptors and achieve high accuracy on their benchmark. The experiment setting is similar to our goal while they conduct text recognition on total $10$ classes (from $0$ to $9$) and need training dataset that contains around $73,000$ digits.

Mishra et al.,~\cite{111} propose a Conditional Random Field model to perform word recognition from candidate bounding boxes of each character obtained in similar method as our work. They impose top-down cues obtained from a lexicon-based prior and the optimal word representation is obtained by minimizing the energy function corresponding to the random field model.

While progress has been made on cropped word recognition recently, the main challenge still lies on ene-to-end word recognition on the full image due to a great amount of unpredictable false positive objects. Our work and experiment setting are based on~\cite{417} that we propose a more robust and reliable character detector to achieve a better scene text recognition on both cropped word and whole word recognition on full image.

%-------------------------------------------------------------------------
\section{Character Detection}

\subsection{Character Detection with SVM}

The first step in our algorithm is to detect potential locations of characters in the input image. In order to detect characters in different fonts and view points, we perform multi-scale and multi-aspect ratio for each character via sliding window classification. There are 62 categories (26 lowercase, 26 uppercase, and 10 digits) in our problem. We need to choose a suitable classifier in order to handle this large amount of categories efficiently. Multi-class Support Vector Machine (SVM) is an robust classifier to deal with multi-class problem. In our implementation, we use Histogram of Gradient (HOG) descriptor~\cite{115} as features and input to SVM.

This sliding window detection method produces many possible locations with different scales and aspect ratios. These are candidate bounding boxes. However, some of those candidate boxes are not useful for recognizing words in the next step. We eliminate those bounding boxes using the following method.

\subsection{Candidate Re-scoring and NMS}

English alphabet tends to have certain aspect ratios for each character. For example, character `I' is usually thinner than `W' and `l' is thinner than `m'. We then adopt this aspect ratio heuristic to re-score those candidate bounding boxes base on their aspect ratios using normal distribution model:
\[
AC(l_i) = \exp \Bigg( \frac{-(\mu_{a_j} - a_i)^2}{2\sigma_{a_j}^2} \Bigg)
\]
where $\mu_{a_j}$ and $\sigma_{a_j}$ are the mean and variance of the aspect ratio (computed from training data) for character $j$ for a window $l_i$ with aspect ratio $a_i$ and $AC(l_i)$ is the aspect ratio probability value. At testing time, all candidate bounding boxes for each character will be re-scored by multiplying the probability score of normal distribution. Confident score of all candidate bounding boxes with unreliable aspect ratios would be suppressed by the probability value.

We then apply Non-Maximum Suppression (NMS) for each character to address the issue of multiple overlapping detection for each instance of a character. Notice that NMS is performed after aspect ratio pruning because wide candidates may contain other thin candidates while thin candidates are true locations and we do not want NMS first eliminate those true but thin candidates.

\begin{figure}[t]
\begin{center}
\includegraphics[width=1\linewidth]{fig/train_data}
\end{center}
   \caption{Examples of truncated training data. Notice that the internal geometric information still preserved after eliminate information on both sides.}
\label{fig:sample1}
\end{figure}

\begin{figure*}[ht]
\begin{center}$
\begin{array}{cc}
\includegraphics[width=1\linewidth]{fig/p13_after}
\end{array}$
\end{center}
\caption{Illustration of character detection and word recognition.}
\label{figure:end-to-end}
\end{figure*}

%-------------------------------------------------------------------------
\section{Word Recognition}

\subsection{Problem setup}

Let $x=(x_{1},...,x_{n})$ be the candidates bounding boxes and $s=(s_{1},...,s_{n})$
be the scores associated with them. We want to find the optimal configuration
that minimizes the following cost function
\begin{eqnarray*}
x^{*} & = & argmin-s^{T}x+x^{T}Ax\\
s.t &  & x_{i}(x_{i}-1)=0\forall i=1...n
\end{eqnarray*}
where A is a cost matrix. The construction of the cost matrix is descirbed in the next section. Given the primal problem, the dual of this problem is derived as followed,
\begin{eqnarray*}
d^{*} & = & max-\frac{1}{2}(s+\lambda)^{T}(A+\mbox{diag}(\lambda))^{\dagger}(s+\lambda)\\
s.t. &  & A+\mbox{diag}(\lambda)\succeq0\\
 &  & s+\lambda\in\Re(A+\mbox{diag(\ensuremath{\lambda}))}
\end{eqnarray*}
The semidefinite programming equivalent of this problem is expressed as followed,

\begin{eqnarray*}
& max & t\\
 & s.t. & \left[\begin{array}{cc}
A+\mbox{diag}(\lambda) & -\frac{1}{4}(s+\lambda)\\
-\frac{1}{4}(s+\lambda) & -t
\end{array}\right]\succeq0
\end{eqnarray*}\\
The dual of the SDP is
\begin{eqnarray*}
 & \mbox{argmin} &  tr(AZ)-\frac{1}{2}s^{T}z\\
 & s.t. & diag(Z)=\frac{1}{2}z\\
 &  & \left[\begin{array}{cc}
Z & z\\
z^{T} & 1
\end{array}\right]\succeq0
\end{eqnarray*}
We treat this SDP problem as a relaxation of the primal problem. After obtaining the solution for the SDP, we search across the values of z as thesholds to minimize the original cost function.
\subsection{Construction of cost matrices}
We construct the cost matrix from three factors: collisions, bigram probability, and the color similarities. Mathematically, the cost matrix is defined as,

\begin{eqnarray*}
A=-\alpha B+\beta C+\gamma S
\end{eqnarray*}
where B, C, and S matrices represent bigram probability, collision, and color similarity, while $\alpha$, $\beta$, and $\gamma$ are the weighting factors.
Collision was factored in the cost matrix as the intuition provides that correct bounding boxes often have little overlaps with another. Figure~\ref{fig:matrix} provides an example where the collision distinction helps in recognition. Mathematically, the collision matrix is constructed as 

\begin{eqnarray*}
C_{ij}=\frac{area_{i}\cap area_{j}}{area_{i}+area_{j}}
\end{eqnarray*}

We construct a bigram model from our lexicon, consisted of 427 words. We want to dampen the bigram effects if the bounding boxes are far away from another. So we multiply the bigram score with the inverse of the Euclidean distance between the bounding box. The bigram matrix is mathematically defined as
\[
B_{ij}=\begin{cases}
\frac{P(l_{i}|l_{j})}{d_{ij}} & x_{i}>x_{j}\\
0 & otherwise
\end{cases}
\]
where $P(l_{i}|l_{j})$ is the probability that the letter $l_{j}$ is followed by $l_{i}$ and $d_{ij}$ is the Euclidean between the bounding boxes. The similarity matrix is constructed by computing the pairwise $\chi^2$ distance the color histogram of each bounding box. We use 15 bins for each color channel.


\begin{figure}
\begin{center}$
\begin{array}{cc}
\includegraphics[width=1\linewidth]{fig/ptop} \\
\end{array}$
\end{center}
\caption{Examples describing the effects of the factors in the cost matrix. Picture (a) shows an example where the bigram would break the tie between both plausible explanation for the words. The bigram would weight the chance of the letter 'D' followed by the letter 'O' high than the digit '9'. Example (b) shows the effects of minizing the overlaps would lead the algorithm to choose 'DO' over 'DK' or 'KO'. Example (c) shows the benifits of the similarity matrix. The bounding box containing the letter 'D' is closer in term of color histogram distance to the bounding box containing the letter 'O' than the letter 'P'. }\label{fig:matrix}
\end{figure}


%-------------------------------------------------------------------------
\section{Experiment}
\subsection{Dataset}

We use the Street View Text (SVT)~\cite{417} dataset in our experiments. The SVT dataset contains images taken from Google Map Street View. The words in SVT images come from local business signs and have high degree of variability in appearance and resolution. There are total $647$ cropped word images from the SVT testing set.

\subsection{Character Detection}

There are many descriptors can be used for character recognition, and we choose the HOG feature as our descriptor that it outperform the others in~\cite{117} because it preserves better geometric information. We densely compute HOG features with a cell size of $8 \times 8$ using $8$ bins after resizing each image to $48 \times 48$ windows. This character detector is trained on ICDAR 2003 dataset, char-74K, and our synthetic data using a one-againt-one SVM classifier with an RBF kernel, where the synthetic data contains about 10,000 images for 62 classes using 40 fonts and for each image we add some amount of Gaussian noise, and apply a random affine deformation. The SVM classifier 3-fold cross validation accuracy is 85\% outperform than Random Ferns classifier which has the accuracy of 52\%.

We then perform sliding window based character detection for multi-scale and multi-aspect ratio for every location in the input image. The candidate bounding boxes obtained by SVM classifier are then re-scored by normal distribution model. NMS is performed on the remaining bounding boxes to avoid wrong elimination. These two steps are simply but efficient to discard noisy candidate while still preserve most true positive candidates for the next word recognition step.

\subsection{Cropped Word Recognition}

Using the character detection and recognition described in previous section, we evaluate our method on the cropped region of the SVT-WD data set. We empirically find that $\alpha=.4$, $\beta=.4$, and $\gamma=.2$ give the best performance. We achieve the accuracy of 52.2\% on the test set. As another metric for our evaluation, we compute the Levenshtein's distance between the prediction and the ground truth. The average edit distance is 2.48. The average length of the words in the lexicon is 5.82.

\begin{table}
\begin{center}
\begin{tabular}{|l|c|}
\hline
Approach & Accuracy \\
\hline\hline
Previous work~\cite{417}  & 0.56 (364 words) \\
Our approach & 0.52 (337 words)\\
\hline
\end{tabular}
\end{center}
\caption{Cropped Word Recognition Accuracy: A comparison of proposed method to PLEX in~\cite{417}. Even thought the accuracy is lower than the previous work, our system dose not directly rely on lexicon but rather just a bigram built from it.}
\label{table:compare}
\end{table}

\subsection{Results and Discussion}

We study the effect of multi-ratio of width and height. Original work in~\cite{417} uses fixed aspect ratio for sliding window approach. We, however, observe that different characters tend to have different ratios between width and height. In order to leverage this feature, multi-ratio of width and height for sliding window is performed in our algorithm. Multi-ratio approach is better at capturing true character bounding boxes in natural image with high variability.

We also analyze the effect of truncated training data. SVM is trained on training data that contain some noise on both sides in~\cite{417} . In real street view cases, characters, however, are tightly connected and it is difficult to contain all possible noise in training step. Therefore, we train our character detector on truncated training data by discarding $0.3$ width information on both sides to capture the internal geometric information. The result shows that we only need the internal information to capture characters in natural street view image and we can avoid the labor of collecting all possible combinations for the noise in both sides in training step.

While our result is worse than the original method, we did not rely much on the lexicon. Our algorithm only leverages from the bigram built from the provided lexicons. Even so, we train our bigram model on the whole lexicon of 427 words, not just 50 words as the original method describes. Due to the restriction on time, we are not able to fully search over our parameter and fully discover the weighting factors in the cost matrices.

After error analysis, we find that noise bounding boxes are still the main cause of confusion in our algorithm. Intra-class confusion is another factor that contributes to the errors. The final main factor that the error is propagated from character detection step. 

\begin{figure}
\begin{center}$
\begin{array}{cc}
\includegraphics[width=1\linewidth]{fig/p9} \\
\includegraphics[width=1\linewidth]{fig/p11} \\
\includegraphics[width=1\linewidth]{fig/p12} \\
\end{array}$
\end{center}
\caption{Experiment results on SVT-WORD dataset.}
\label{figure:result1}
\end{figure}

%-------------------------------------------------------------------------
\section{Conclusion}

In this paper, we investigate a new approach toward scene text recognition. We implement a sliding window character classifier using SVM with HOG features. Using the bounding boxes obtained from character classifier, we set up a convex optimization problem, which is a relaxation of boolean quadratic programming problem to select the best candidate bounding boxes.

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
